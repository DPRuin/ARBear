/*
See LICENSE folder for this sampleâ€™s licensing information.

Abstract:
Main view controller for the AR experience.
*/

import ARKit
import SceneKit
import UIKit
import Photos

class ARViewController: UIViewController {
    
    // MARK: IBOutlets
    
    @IBOutlet var sceneView: VirtualObjectARView!
    @IBOutlet weak var addObjectButton: UIButton!
    @IBOutlet weak var blurView: UIVisualEffectView!
    @IBOutlet weak var spinner: UIActivityIndicatorView!

    @IBOutlet weak var imageView: UIImageView!
    
    /// å½•åˆ¶ç›¸å…³
    var recorder:RecordAR?
    let recordingQueue = DispatchQueue(label: "recordingThread", attributes: .concurrent)
    @IBOutlet weak var squishButton: SquishButton!
    @IBOutlet weak var progressView: UIProgressView!
    
    /// å½•åˆ¶æ—¶é—´
    var count: Float!
    /// å®šæ—¶å™¨
    var timer: Timer!
    /// æœ€å¤§å½•åˆ¶æ—¶é—´
    let maxVideoTime: Float = 10.0
    
    // MARK: - UI Elements
    
    var focusSquare = FocusSquare()
    
    /// The view controller that displays the status and "restart experience" UI.
    lazy var statusViewController: StatusViewController = {
        return childViewControllers.lazy.flatMap({ $0 as? StatusViewController }).first!
    }()
    
    // MARK: - ARKit Configuration Properties
    
    /// A type which manages gesture manipulation of virtual content in the scene.
    lazy var virtualObjectInteraction = VirtualObjectInteraction(sceneView: sceneView)
    
    /// Coordinates the loading and unloading of reference nodes for virtual objects.
    let virtualObjectLoader = VirtualObjectLoader()
    
    /// Marks if the AR experience is available for restart.
    var isRestartAvailable = true
    
    /// é˜Ÿåˆ—ï¼Œç”¨äºåè°ƒæ·»åŠ æˆ–åˆ é™¤åœºæ™¯ä¸­çš„èŠ‚ç‚¹ã€‚
    let updateQueue = DispatchQueue(label: "com.example.apple-samplecode.arkitexample.serialSceneKitQueue")
    
    var screenCenter: CGPoint {
        let bounds = sceneView.bounds
        return CGPoint(x: bounds.midX, y: bounds.midY)
    }
    
    /// Convenience accessor for the session owned by ARSCNView.
    var session: ARSession {
        return sceneView.session
    }
    
    let configuration = ARWorldTrackingConfiguration()
    
    private var nowImage: UIImage!
    private var nowVedioUrl: URL!
    private var isVedio: Bool!
    
    /// æ’­æ”¾å™¨
    fileprivate var player = Player()
    private weak var bgImageView: UIImageView!
    
    /// å¾®åšæ¶ˆæ¯ä½“
    var messageObject: WBMessageObject!
    var ummessageObject: AnyObject!
    
    deinit {
        self.player.willMove(toParentViewController: self)
        self.player.view.removeFromSuperview()
        self.player.removeFromParentViewController()
    }
    
    // MARK: - View Controller Life Cycle
    
    override func viewDidLoad() {
        super.viewDidLoad()
        // è®¾ç½®æ’­æ”¾å™¨
        setupPlayer()
        
        sceneView.delegate = self
        sceneView.session.delegate = self

        // Set up scene content.
        setupCamera()
        sceneView.scene.rootNode.addChildNode(focusSquare)

        sceneView.automaticallyUpdatesLighting = false
        if let environmentMap = UIImage(named: "Models.scnassets/sharedImages/environment_blur.exr") {
            sceneView.scene.lightingEnvironment.contents = environmentMap
        }

        // Hook up status view controller callback(s).
        statusViewController.restartExperienceHandler = { [unowned self] in
            self.restartExperience()
        }
        // å…³é—­
        statusViewController.closeBtnClickHandler = {
            self.dismiss(animated: true, completion: nil)
        }
        
        let tapGesture = UITapGestureRecognizer(target: self, action: #selector(showVirtualObjectSelectionViewController))
        // Set the delegate to ensure this gesture is only used when there are no virtual objects in the scene.
        tapGesture.delegate = self
        sceneView.addGestureRecognizer(tapGesture)
        
        // å½•åˆ¶è®¾ç½®
        setupRecorder()
        setupRecordUI()

        // å•å‡»block
        virtualObjectInteraction.oneTapGestureHandler = {
            // self.showVirtualObjectSelectionViewController()
            self.tapToShowVirtualObject()
        }
        
        addObjectButton.setImage(UIImage(named: "Images.bundle/add"), for: [])
        addObjectButton.setImage(UIImage(named: "Images.bundle/addPressed"), for: [.highlighted])
        
        // åˆ†äº«é¢æ¿è®¾ç½®
        setPreDefinePlatforms()
    }
    
    override func viewWillAppear(_ animated: Bool) {
        super.viewWillAppear(animated)
        
        // å½•åˆ¶
        recorder?.prepare(configuration)
    }

    override func viewDidAppear(_ animated: Bool) {
        super.viewDidAppear(animated)
        
        guard ARWorldTrackingConfiguration.isSupported else {
            fatalError("è®¾å¤‡ä¸æ”¯æŒ")
        }
        
        // Prevent the screen from being dimmed to avoid interuppting the AR experience.
        UIApplication.shared.isIdleTimerDisabled = true

        // Start the `ARSession`.
        resetTracking()
    }
    
    override func viewWillDisappear(_ animated: Bool) {
        super.viewWillDisappear(animated)

        session.pause()
        
        // å½•åˆ¶
        if recorder?.status == .recording {
            recorder?.stopAndExport()
        }
        recorder?.onlyRenderWhileRecording = true
        recorder?.prepare(ARWorldTrackingConfiguration())
        
        // Switch off the orientation lock for UIViewControllers with AR Scenes
        recorder?.rest()
    }
    
    /// å•å‡»åˆ‡æ¢å·²ä¸‹è½½çš„åŠ¨ç”»
    func tapToShowVirtualObject() {
        guard let beforeObject = self.virtualObjectLoader.loadedObjects.first  else {
            return
        }
        let cachesObjects = VirtualObject.availableCachesObjects()
        if cachesObjects.count <= 0 {return}
        
        // è·å–ä¸‹ä¸€ä¸ª
        let cachesObject = cachesObjects.filter({ (object) -> Bool in
            print("--\(object.modelName)--\(beforeObject.modelName)")
            return object.modelName == beforeObject.modelName
        }).first!
        
        let index = cachesObjects.index(of: cachesObject)
        print("--index\(index)")
        var nowIndex = 0
        if index == cachesObjects.count - 1 {
            nowIndex = 0
        } else {
            nowIndex = index! + 1
        }
        let showObject = cachesObjects[nowIndex]
        print("-b-\(self.virtualObjectLoader.loadedObjects.count)")
        // åˆ é™¤åŸæ¥çš„æ¨¡å‹
        self.virtualObjectLoader.removeAllVirtualObjects()
        print("-n-\(self.virtualObjectLoader.loadedObjects.count)")
        
        // æ”¾ç½®é€‰ä¸­çš„æ¨¡å‹
        self.virtualObjectLoader.loadVirtualObject(showObject, loadedHandler: { [unowned self] loadedObject in
            DispatchQueue.main.async {
                self.hideObjectLoadingUI()
                self.placeVirtualObject(loadedObject)
            }
        })
        
        self.displayObjectLoadingUI()
    }
    
    /// è®¾ç½®æ’­æ”¾å™¨
    private func setupPlayer() {
        self.player.view.frame = self.view.bounds
        self.addChildViewController(self.player)
        self.view.addSubview(self.player.view)
        self.player.didMove(toParentViewController: self)
        
        self.player.playbackLoops = true
        self.player.playbackResumesWhenEnteringForeground = false
        self.player.playbackResumesWhenBecameActive = false
        
        let bgImageView = UIImageView(frame: self.view.bounds)
        bgImageView.isHidden = true
        self.bgImageView = bgImageView
        
        self.player.view.addSubview(bgImageView)
        
        // å–æ¶ˆæŒ‰é’®
        let cancelBtn = UIButton(type: .custom)
        cancelBtn.setImage(UIImage(named: "Images.bundle/btn_cancel"), for: UIControlState.normal)
        cancelBtn.addTarget(self, action: #selector(self.btnAfreshDidClick(_:)), for: .touchUpInside)
        
        let insert:CGFloat = 50.0
        let y = self.view.bounds.height - 44/2 - insert
        cancelBtn.frame = CGRect(x: insert - 44/2, y: y, width: 44, height: 44)
        self.player.view.addSubview(cancelBtn)
        
        // ç¡®è®¤æŒ‰é’®
        let confirmBtn = UIButton(type: .custom)
        confirmBtn.setImage(UIImage(named: "Images.bundle/btn_confirm"), for: UIControlState.normal)
        confirmBtn.addTarget(self, action: #selector(self.btnEnsureDidClick(_:)), for: .touchUpInside)
        
        let x = self.view.bounds.width - 44/2 - insert
        confirmBtn.frame = CGRect(x: x, y: y, width: 44, height: 44)
        self.player.view.addSubview(confirmBtn)
        
        // åˆ†äº«æŒ‰é’®
        let shareButton = UIButton(type: .custom)
        let shareX = self.view.bounds.width / 2 - 44/2
        shareButton.frame = CGRect(x: shareX, y: y, width: 44, height: 44)
        shareButton.setImage(UIImage(named: "Images.bundle/btn_share"), for: UIControlState.normal)
        shareButton.addTarget(self, action: #selector(self.btnShareDidClick(_:)), for: .touchUpInside)
        self.player.view.addSubview(shareButton)
        
        
        
    }
    
    // MARK: - å½•åˆ¶æŒ‰é’®ç‚¹å‡»
    
    @objc func squishButtonTouchUpInside(sender: UIButton) {
        print("squishButtonTouchUpInside")
        // æ‹ç…§
        squishButton.type = ButtonType.camera
        
        isVedio = false
        
        nowImage = self.recorder?.photo()
        self.player.url = Bundle.main.url(forResource: "playerneed", withExtension: "mp4")
        self.player.playFromBeginning()
        self.player.pause()
        bgImageView.isHidden = false
        bgImageView.image = nowImage
        
    }
    
    @objc func squishButtonLongPress(gesture: UILongPressGestureRecognizer) {
        
        if gesture.state == .began { // å¼€å§‹å½•åˆ¶è§†é¢‘
            print("longpressbegan")
            squishButton.type = ButtonType.video
            
            progressView.isHidden = false
            // è®¡æ—¶
            count = 0
            timer = Timer.scheduledTimer(timeInterval: 0.1, target: self, selector: #selector(self.handleTimer(sender:)), userInfo: nil, repeats: true)
            timer.fire()
            
            isVedio = true
            
            // Record
            if recorder?.status == .readyToRecord { // å¼€å§‹å½•åˆ¶
                
                recordingQueue.async {
                    self.recorder?.record()
                }
            }
            
        } else if gesture.state == .ended { // ç»“æŸå½•åˆ¶è§†é¢‘
            print("longpressended")
            squishButton.type = ButtonType.camera
            
            timer.invalidate()
            print("-count-\(count)")
            progressView.isHidden = true
            
            // recorder
            if recorder?.status == .recording { // åœæ­¢å½•åˆ¶
                
                recorder?.stop({ (url) in
                    DispatchQueue.main.async {
                        self.bgImageView.isHidden = true
                    }
                    
                    self.nowVedioUrl = url
                    self.player.url = url
                    self.player.playFromBeginning()
                })
            }
        }
        
    }
    
    @objc func handleTimer(sender: Timer) {
        count = count + 0.1
        if maxVideoTime > count { // ç»§ç»­å½•åˆ¶è§†é¢‘
            progressView.progress = count / maxVideoTime
            
        } else { // åœæ­¢å½•åˆ¶è§†é¢‘
            let gesture = squishButton.gestureRecognizers?.filter({ (gesture) -> Bool in
                return gesture is UILongPressGestureRecognizer
            }).first as! UILongPressGestureRecognizer
            
            gesture.state = .ended
            print("åˆ°æ—¶é—´äº†")
        }
    }
    
    @objc func btnAfreshDidClick(_ sender: UIButton) {
        self.player.pause()
        self.player.view.isHidden = true
    }
    
    @objc func btnEnsureDidClick(_ sender: UIButton) {
        self.player.pause()
        self.player.view.isHidden = true
        
        if isVedio {
            recorder?.export(video: nowVedioUrl, { (saved, status) in
                DispatchQueue.main.sync {
                    self.exportMessage(success: saved, status: status)
                }
            })
            
        } else {
            self.recorder?.export(UIImage: nowImage) { saved, status in
                if saved {
                    self.exportMessage(success: saved, status: status)
                }
            }
        }
    }
    
    /// åˆ†äº«
    @objc func btnShareDidClick(_ sender: UIButton) {
//        if isVedio {
//            messageObject = weiboVideoMessage(videoUrl: nowVedioUrl)
//        } else {
//            messageObject = weiboImageMessage(images: [nowImage])
//        }
        
        // UIActivityIndicatorView è®¾ç½®æŒ‡ç¤ºå™¨
        
        if isVedio {
            ummessageObject = nowVedioUrl as AnyObject
        } else {
            ummessageObject = nowImage
        }
        // å±•ç¤ºå‹ç›Ÿåˆ†äº«é¢æ¿
        showUM()
        
    }
    
    // MARK: - Exported UIAlert present method
    func exportMessage(success: Bool, status:PHAuthorizationStatus) {
        if success {
            let alert = UIAlertController(title: "å¯¼å‡º", message: "å¯¼å‡ºç›¸å†ŒæˆåŠŸ", preferredStyle: .alert)
            alert.addAction(UIAlertAction(title: "ok", style: .cancel, handler: nil))
            self.present(alert, animated: true, completion: nil)
        }else if status == .denied || status == .restricted || status == .notDetermined {
            let errorView = UIAlertController(title: "ğŸ˜…", message: "ç›¸å†Œæƒé™", preferredStyle: .alert)
            let settingsBtn = UIAlertAction(title: "OpenSettings", style: .cancel) { (_) -> Void in
                guard let settingsUrl = URL(string: UIApplicationOpenSettingsURLString) else {
                    return
                }
                if UIApplication.shared.canOpenURL(settingsUrl) {
                    if #available(iOS 10.0, *) {
                        UIApplication.shared.open(settingsUrl, completionHandler: { (success) in
                        })
                    } else {
                        UIApplication.shared.openURL(URL(string:UIApplicationOpenSettingsURLString)!)
                    }
                }
            }
            errorView.addAction(UIAlertAction(title: "Later", style: UIAlertActionStyle.default, handler: {
                (UIAlertAction)in
            }))
            errorView.addAction(settingsBtn)
            self.present(errorView, animated: true, completion: nil)
        }else{
            let alert = UIAlertController(title: "Exporting Failed", message: "There was an error while exporting your media file.", preferredStyle: .alert)
            alert.addAction(UIAlertAction(title: "OK", style: .cancel, handler: nil))
            self.present(alert, animated: true, completion: nil)
        }
    }
    
    /// MARK: - ARVideoKit
    func setupRecorder() {
        // Initialize ARVideoKit recorder
        recorder = RecordAR(ARSceneKit: sceneView)
        
        /*----ğŸ‘‡---- ARVideoKit Configuration ----ğŸ‘‡----*/
        
        // Set the recorder's delegate
        recorder?.delegate = self
        
        // Set the renderer's delegate
        recorder?.renderAR = self
        
        // Configure the renderer to perform additional image & video processing ğŸ‘
        recorder?.onlyRenderWhileRecording = false
        
        // Configure ARKit content mode. Default is .auto
        recorder?.contentMode = .aspectFill
        
        // Set the UIViewController orientations
        recorder?.inputViewOrientations = [.landscapeLeft, .landscapeRight, .portrait]
        // Configure RecordAR to store media files in local app directory
        recorder?.deleteCacheWhenExported = false
    }
    
    /// è®¾ç½®å½•åˆ¶UI
    func setupRecordUI() {
        progressView.progress = 0
        progressView.isHidden = true
        progressView.progressTintColor = UIColor.red
        
        squishButton.addTarget(self, action: #selector(self.squishButtonTouchUpInside(sender:)), for: UIControlEvents.touchUpInside)
        let longPress = UILongPressGestureRecognizer(target: self, action: #selector(squishButtonLongPress(gesture:)))
        // å®šä¹‰é•¿æŒ‰0.8æ—¶é—´è§¦å‘
        longPress.minimumPressDuration = 0.8
        squishButton.addGestureRecognizer(longPress)
        
    }
    
    // MARK: - Scene content setup

    func setupCamera() {
        guard let camera = sceneView.pointOfView?.camera else {
            fatalError("Expected a valid `pointOfView` from the scene.")
        }

        /*
         Enable HDR camera settings for the most realistic appearance
         with environmental lighting and physically based materials.
         */
        camera.wantsHDR = true
        camera.exposureOffset = -1
        camera.minimumExposure = -1
        camera.maximumExposure = 3
    }

    // MARK: - Session management
    
    /// Creates a new AR configuration to run on the `session`.
    func resetTracking() {
        
        configuration.planeDetection = .horizontal
        session.run(configuration, options: [.resetTracking, .removeExistingAnchors])

        statusViewController.scheduleMessage("å¯»æ‰¾å¹³é¢å»æ”¾ç½®ç‰©ä½“", inSeconds: 7.5, messageType: .planeEstimation)
    }

    // MARK: - Focus Square

    func updateFocusSquare() {
        let isObjectVisible = virtualObjectLoader.loadedObjects.contains { object in
            return sceneView.isNode(object, insideFrustumOf: sceneView.pointOfView!)
        }
        
        if isObjectVisible {
            focusSquare.hide()
        } else {
            focusSquare.unhide()
            statusViewController.scheduleMessage("å°è¯•å·¦å³ç§»åŠ¨æ‰‹æœº", inSeconds: 5.0, messageType: .focusSquare)
        }
        
        // We should always have a valid world position unless the sceen is just being initialized.
        // é™¤éå±å¹•åˆå§‹åŒ–ï¼Œ å¦åˆ™æˆ‘ä»¬åº”è¯¥æ‹¥æœ‰ä¸€ä¸ªæœ‰æ•ˆçš„ä¸–ç•Œä½ç½®
        guard let (worldPosition, planeAnchor, _) = sceneView.worldPosition(fromScreenPosition: screenCenter, objectPosition: focusSquare.lastPosition) else {
            updateQueue.async {
                self.focusSquare.state = .initializing
                self.sceneView.pointOfView?.addChildNode(self.focusSquare)
            }
            addObjectButton.isHidden = true
            return
        }
        
        updateQueue.async {
            self.sceneView.scene.rootNode.addChildNode(self.focusSquare)
            let camera = self.session.currentFrame?.camera
            
            if let planeAnchor = planeAnchor {
                self.focusSquare.state = .planeDetected(anchorPosition: worldPosition, planeAnchor: planeAnchor, camera: camera)
            } else {
                self.focusSquare.state = .featuresDetected(anchorPosition: worldPosition, camera: camera)
            }
        }
        addObjectButton.isHidden = false
        statusViewController.cancelScheduledMessage(for: .focusSquare)
    }
    
    // MARK: - Error handling
    
    func displayErrorMessage(title: String, message: String) {
        // Blur the background.
        blurView.isHidden = false
        
        // Present an alert informing about the error that has occurred.
        let alertController = UIAlertController(title: title, message: message, preferredStyle: .alert)
        let restartAction = UIAlertAction(title: "é‡æ–°å¯åŠ¨ä¼šè¯", style: .default) { _ in
            alertController.dismiss(animated: true, completion: nil)
            self.blurView.isHidden = true
            self.resetTracking()
        }
        alertController.addAction(restartAction)
        present(alertController, animated: true, completion: nil)
    }

}

//MARK: - ARVideoKit Delegate Methods
extension ARViewController: RecordARDelegate, RenderARDelegate {
    func frame(didRender buffer: CVPixelBuffer, with time: CMTime, using rawBuffer: CVPixelBuffer) {
        // Do some image/video processing.
    }
    
    func recorder(didEndRecording path: URL, with noError: Bool) {
        if noError {
            // Do something with the video path.
        }
    }
    
    func recorder(didFailRecording error: Error?, and status: String) {
        // Inform user an error occurred while recording.
    }
    
    func recorder(willEnterBackground status: RecordARStatus) {
        // Use this method to pause or stop video recording. Check [applicationWillResignActive(_:)](https://developer.apple.com/documentation/uikit/uiapplicationdelegate/1622950-applicationwillresignactive) for more information.
        if status == .recording {
            recorder?.stopAndExport()
        }
    }
}
